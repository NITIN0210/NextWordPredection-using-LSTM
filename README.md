# NextWordPredection using LSTM
This repository contains a Keras implementation of an LSTM-based word prediction model. The model is trained to predict the next word in a sequence based on the preceding words.

### Model Architecture
Embedding Layer: Converts input words into dense vectors for representation.

LSTM Layers: Two LSTM layers capture long-term dependencies in the sequential data.

Dense Layers: Feature extraction and prediction layers.

Compilation: Categorical cross-entropy loss, Adam optimizer.

Summary: Model architecture and parameters overview.

#### Usage
Load the pre-trained model.
Compile with appropriate settings.
Fit the model to your data.
Feel free to customize the architecture and parameters to suit your needs.
